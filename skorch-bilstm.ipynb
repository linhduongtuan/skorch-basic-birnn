{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, autograd\n",
    "from torch.nn import functional as F\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.helper import predefined_split\n",
    "from skorch.callbacks import EarlyStopping\n",
    "\n",
    "from nltk import casual_tokenize\n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SPLIT = 2\n",
    "MSG_LEN = 20\n",
    "EMBED_DIM = 300\n",
    "HIDDEN_DIM = 100\n",
    "NUM_LAYERS = 2\n",
    "VOCAB_SIZE = 100000\n",
    "OOV_IDX = 0\n",
    "EOS_IDX = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wvs(embeddings_path: str, embedding_dim: int, limit=None):\n",
    "    if limit is not None:\n",
    "        limit = int(limit)\n",
    "    with open(embeddings_path) as infile:\n",
    "        if next(infile).split(\" \") == embeddings_path:\n",
    "            # Skip header for fasttext, don't for glove\n",
    "            infile.seek(0)\n",
    "        return pd.read_csv(\n",
    "            infile,\n",
    "            header=None,\n",
    "            delim_whitespace=True,\n",
    "            names=list(range(embedding_dim)),\n",
    "            quoting=csv.QUOTE_NONE,\n",
    "            nrows=limit,\n",
    "            index_col=0,\n",
    "        )\n",
    "\n",
    "\n",
    "all_embeds = load_wvs(\"embeddings.txt\", EMBED_DIM, VOCAB_SIZE)\n",
    "raw_embeds = np.vstack([np.zeros(EMBED_DIM), all_embeds.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_idxs = {tok: idx + 1 for idx, tok in enumerate(all_embeds.index.values.tolist())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(text):\n",
    "    idxs = [token_idxs.get(tok, OOV_IDX) for tok in text.split(' ')[:MSG_LEN]]\n",
    "    return np.array(idxs + [EOS_IDX] * (MSG_LEN - len(idxs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(topic_num: int):\n",
    "    df = pd.read_csv(\"data/{}.csv\".format(topic_num))\n",
    "    presents = df[df[\"present\"] == 1]\n",
    "    missings = df[df[\"present\"] == 0]\n",
    "    train = pd.concat(\n",
    "        [\n",
    "            presents.iloc[: int(presents.shape[0] // TRAIN_SPLIT)],\n",
    "            missings.iloc[: int(missings.shape[0] // TRAIN_SPLIT)],\n",
    "        ],\n",
    "        axis=\"rows\",\n",
    "    )\n",
    "    validation = pd.concat(\n",
    "        [\n",
    "            presents.iloc[int(presents.shape[0] // TRAIN_SPLIT) :],\n",
    "            missings.iloc[int(missings.shape[0] // TRAIN_SPLIT) :],\n",
    "        ],\n",
    "        axis=\"rows\",\n",
    "    )\n",
    "    return train, validation\n",
    "\n",
    "\n",
    "def make_x_and_y(dataset):\n",
    "    x = [vectorize(text) for text in dataset['text'].values.tolist()]\n",
    "    y = dataset['present'].values\n",
    "    return torch.LongTensor(np.vstack(x).astype(np.int64)), \\\n",
    "        torch.LongTensor(y.astype(np.int64))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, validation = make_dataset(36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_x, training_y = make_x_and_y(training)\n",
    "validation_x, validation_y = make_x_and_y(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([65, 20]), torch.Size([65]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_x.shape, training_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prf1(predictions, true):\n",
    "    p = precision_score(predictions, true)\n",
    "    r = recall_score(predictions, true)\n",
    "    f1 = 2 * p * r / (p + r)\n",
    "    return p, r, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, num_units=10, nonlin=F.relu):\n",
    "        super().__init__()\n",
    "        self.word_embeddings = nn.Embedding(VOCAB_SIZE + 1, embedding_dim=EMBED_DIM)\n",
    "        self.word_embeddings.weight = nn.Parameter(torch.FloatTensor(raw_embeds))\n",
    "        self.word_embeddings.weight.requires_grad = False\n",
    "        self.lstm = nn.GRU(\n",
    "            EMBED_DIM,\n",
    "            HIDDEN_DIM,\n",
    "            num_layers=NUM_LAYERS,\n",
    "            dropout=0.2,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "        )\n",
    "        self.softmax = nn.Linear(HIDDEN_DIM * 4, 2)\n",
    "        self.dropout = nn.Dropout2d(0.1)\n",
    "        self.hidden = self.init_hidden()\n",
    "    \n",
    "        print(sum(param.nelement() for param in self.lstm.parameters()))\n",
    "            \n",
    "\n",
    "    def forward(self, doc):\n",
    "        embeds = self.word_embeddings(doc)\n",
    "        if self.training:\n",
    "            embeds = self.dropout(embeds.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "        lstm_out, self.hidden = self.lstm(embeds)\n",
    "        tag_space = self.softmax(\n",
    "            torch.cat(\n",
    "                [\n",
    "                    torch.max(self.dropout(lstm_out), 1)[0],\n",
    "                    torch.mean(self.dropout(lstm_out), 1),\n",
    "                ],\n",
    "                1,\n",
    "            )\n",
    "        )\n",
    "        tag_scores = F.softmax(tag_space, dim=-1)\n",
    "        return tag_scores\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (\n",
    "            autograd.Variable(torch.zeros(2, 1, HIDDEN_DIM)),\n",
    "            autograd.Variable(torch.zeros(2, 1, HIDDEN_DIM)),\n",
    "        )\n",
    "\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "    Classifier,\n",
    "    batch_size=32,\n",
    "    max_epochs=100,\n",
    "    lr=0.2,\n",
    "    train_split=predefined_split(Dataset(validation_x, validation_y)),\n",
    "    callbacks=[EarlyStopping(patience=5, monitor='valid_loss')],\n",
    "    device='cuda',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422400\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5619\u001b[0m       \u001b[32m0.8060\u001b[0m        \u001b[35m0.5481\u001b[0m  0.0612\n",
      "      2        0.7486       0.8060        \u001b[35m0.5132\u001b[0m  0.0376\n",
      "      3        0.6660       0.8060        \u001b[35m0.4971\u001b[0m  0.0443\n",
      "      4        0.6190       0.8060        \u001b[35m0.4858\u001b[0m  0.0474\n",
      "      5        0.6004       0.8060        \u001b[35m0.4770\u001b[0m  0.0403\n",
      "      6        0.5820       0.8060        \u001b[35m0.4719\u001b[0m  0.0610\n",
      "      7        0.5688       0.8060        \u001b[35m0.4663\u001b[0m  0.0422\n",
      "      8        \u001b[36m0.5603\u001b[0m       0.8060        \u001b[35m0.4635\u001b[0m  0.0473\n",
      "      9        \u001b[36m0.5374\u001b[0m       0.8060        \u001b[35m0.4599\u001b[0m  0.0380\n",
      "     10        0.5466       0.8060        \u001b[35m0.4548\u001b[0m  0.0469\n",
      "     11        \u001b[36m0.5262\u001b[0m       0.8060        \u001b[35m0.4521\u001b[0m  0.0373\n",
      "     12        \u001b[36m0.5221\u001b[0m       0.8060        \u001b[35m0.4479\u001b[0m  0.0460\n",
      "     13        \u001b[36m0.5133\u001b[0m       0.8060        \u001b[35m0.4440\u001b[0m  0.0394\n",
      "     14        \u001b[36m0.5093\u001b[0m       0.8060        \u001b[35m0.4395\u001b[0m  0.0470\n",
      "     15        \u001b[36m0.5003\u001b[0m       0.8060        \u001b[35m0.4357\u001b[0m  0.0431\n",
      "     16        \u001b[36m0.4931\u001b[0m       0.8060        \u001b[35m0.4324\u001b[0m  0.0404\n",
      "     17        \u001b[36m0.4811\u001b[0m       0.8060        \u001b[35m0.4283\u001b[0m  0.0406\n",
      "     18        0.4813       0.8060        \u001b[35m0.4213\u001b[0m  0.0441\n",
      "     19        \u001b[36m0.4624\u001b[0m       0.8060        \u001b[35m0.4170\u001b[0m  0.0507\n",
      "     20        \u001b[36m0.4598\u001b[0m       0.8060        \u001b[35m0.4110\u001b[0m  0.0390\n",
      "     21        \u001b[36m0.4520\u001b[0m       0.8060        \u001b[35m0.4080\u001b[0m  0.0509\n",
      "     22        \u001b[36m0.4503\u001b[0m       0.8060        \u001b[35m0.3999\u001b[0m  0.0401\n",
      "     23        \u001b[36m0.4115\u001b[0m       0.8060        \u001b[35m0.3961\u001b[0m  0.0483\n",
      "     24        0.4242       0.8060        \u001b[35m0.3891\u001b[0m  0.0390\n",
      "     25        \u001b[36m0.4043\u001b[0m       0.8060        0.3893  0.0451\n",
      "     26        \u001b[36m0.3921\u001b[0m       0.8060        \u001b[35m0.3791\u001b[0m  0.0470\n",
      "     27        \u001b[36m0.3811\u001b[0m       0.8060        \u001b[35m0.3775\u001b[0m  0.0525\n",
      "     28        \u001b[36m0.3774\u001b[0m       0.8060        \u001b[35m0.3723\u001b[0m  0.0410\n",
      "     29        \u001b[36m0.3624\u001b[0m       0.8060        \u001b[35m0.3620\u001b[0m  0.0451\n",
      "     30        \u001b[36m0.3299\u001b[0m       \u001b[32m0.8209\u001b[0m        \u001b[35m0.3536\u001b[0m  0.0396\n",
      "     31        \u001b[36m0.3101\u001b[0m       0.8209        \u001b[35m0.3516\u001b[0m  0.0422\n",
      "     32        \u001b[36m0.2890\u001b[0m       0.8209        \u001b[35m0.3394\u001b[0m  0.0403\n",
      "     33        \u001b[36m0.2859\u001b[0m       0.8209        \u001b[35m0.3367\u001b[0m  0.0417\n",
      "     34        \u001b[36m0.2150\u001b[0m       0.8209        \u001b[35m0.3013\u001b[0m  0.0544\n",
      "     35        \u001b[36m0.1971\u001b[0m       0.8209        0.3174  0.0398\n",
      "     36        \u001b[36m0.1740\u001b[0m       \u001b[32m0.8806\u001b[0m        \u001b[35m0.2886\u001b[0m  0.0394\n",
      "     37        \u001b[36m0.1669\u001b[0m       0.8657        0.2926  0.0508\n",
      "     38        \u001b[36m0.1542\u001b[0m       0.8657        0.2939  0.0434\n",
      "     39        \u001b[36m0.1431\u001b[0m       \u001b[32m0.9104\u001b[0m        \u001b[35m0.2731\u001b[0m  0.0446\n",
      "     40        \u001b[36m0.1097\u001b[0m       0.9104        \u001b[35m0.2640\u001b[0m  0.0446\n",
      "     41        \u001b[36m0.0955\u001b[0m       0.9104        \u001b[35m0.2630\u001b[0m  0.0445\n",
      "     42        0.1010       0.9104        0.2658  0.0490\n",
      "     43        0.1017       0.9104        \u001b[35m0.2466\u001b[0m  0.0531\n",
      "     44        \u001b[36m0.0686\u001b[0m       0.9104        0.2525  0.0487\n",
      "     45        0.0708       0.9104        0.2686  0.0472\n",
      "     46        \u001b[36m0.0619\u001b[0m       0.9104        0.2486  0.0527\n",
      "     47        0.0646       0.9104        0.2603  0.0454\n",
      "     48        0.0740       0.9104        \u001b[35m0.2451\u001b[0m  0.0455\n",
      "     49        \u001b[36m0.0537\u001b[0m       0.9104        0.2597  0.0552\n",
      "     50        \u001b[36m0.0518\u001b[0m       \u001b[32m0.9254\u001b[0m        \u001b[35m0.2401\u001b[0m  0.0605\n",
      "     51        \u001b[36m0.0398\u001b[0m       0.9254        0.2425  0.0532\n",
      "     52        0.0563       0.9104        \u001b[35m0.2379\u001b[0m  0.0542\n",
      "     53        0.0414       0.9104        0.2541  0.0458\n",
      "     54        0.0460       0.9104        0.2407  0.0426\n",
      "     55        0.0431       0.9104        0.2422  0.0460\n",
      "     56        \u001b[36m0.0363\u001b[0m       0.9104        0.2717  0.0455\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=Classifier(\n",
       "    (word_embeddings): Embedding(100001, 300)\n",
       "    (lstm): GRU(300, 100, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "    (softmax): Linear(in_features=400, out_features=2, bias=True)\n",
       "    (dropout): Dropout2d(p=0.1)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(training_x, training_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5384615384615384, 1.0, 0.7000000000000001)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('validation')\n",
    "prf1(net.predict(validation_x), validation_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0, 1.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('training')\n",
    "prf1(net.predict(training_x), training_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.predict(torch.LongTensor(np.vstack([\n",
    "    vectorize('she was not professional'),\n",
    "    vectorize('she was not very professional'),\n",
    "    vectorize('he was not very professional'),\n",
    "    vectorize('he was very rude'),\n",
    "    vectorize('she was very rude'),\n",
    "    vectorize('he was very unprofessional'),\n",
    "    vectorize('they were very condescending'),\n",
    "    vectorize('she was very condescending'),\n",
    "])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.batch_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.1 s, sys: 509 ms, total: 2.61 s\n",
      "Wall time: 2.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_ = net.predict(torch.cat([validation_x] * 1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([67000, 20])\n"
     ]
    }
   ],
   "source": [
    "print(torch.cat([validation_x] * 1000).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu tokens processed per second: 515384.6153846154\n"
     ]
    }
   ],
   "source": [
    "print('gpu tokens processed per second:', 67000 * MSG_LEN / 2.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1099,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu tokens processed per second: 10000.0\n"
     ]
    }
   ],
   "source": [
    "print('cpu tokens processed per second:', 6700 * MSG_LEN / 4 / 3.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
